{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08846a07",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an \n",
    "example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb0358c",
   "metadata": {},
   "source": [
    "Simple linear regression is a statistical method that helps to model the relationship between two variables by fitting a straight line to the data. The goal is to find a linear relationship between the independent variable (also called the predictor variable) and the dependent variable (also called the response variable). For example, we can use simple linear regression to model the relationship between the height of a person and their weight.\n",
    "\n",
    "On the other hand, multiple linear regression is a statistical method that helps to model the relationship between two or more independent variables and a dependent variable by fitting a linear equation to the data. The goal is to find a linear relationship between the independent variables and the dependent variable. For example, we can use multiple linear regression to model the relationship between the price of a house and its size, number of bedrooms, and the location of the house.\n",
    "\n",
    "Here are some examples to illustrate the difference between simple linear regression and multiple linear regression:\n",
    "\n",
    "Example of Simple Linear Regression:\n",
    "\n",
    "Suppose we want to understand the relationship between the number of hours a student studies and the grade they get on an exam. We can use simple linear regression to model this relationship. We can collect data on the number of hours a student studies and their corresponding exam grades. We can then plot this data on a scatter plot and fit a straight line that best describes the relationship between the two variables. We can use this line to make predictions about a student's grade based on the number of hours they study.\n",
    "\n",
    "Example of Multiple Linear Regression:\n",
    "\n",
    "Suppose we want to understand the relationship between a person's income and their age, education, and work experience. We can use multiple linear regression to model this relationship. We can collect data on a person's income, age, education level, and work experience. We can then fit a linear equation to this data that takes into account all three independent variables. This equation can be used to make predictions about a person's income based on their age, education, and work experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32cc1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Simple Linear Regression:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate random data\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape((-1, 1))\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Create a model and fit the data\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using the model\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Plot the data and the line of best fit\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, y_pred, color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225d1565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.]\n"
     ]
    }
   ],
   "source": [
    "#Multiple Linear Regression:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate random data\n",
    "X = np.array([[1, 2, 3], [2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]])\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Create a model and fit the data\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using the model\n",
    "X_new = np.array([[6, 12, 18]])\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "# Print the predicted value\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea29d4",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in \n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8dcef",
   "metadata": {},
   "source": [
    "Linear regression is a powerful statistical method for modeling the relationship between a dependent variable and one or more independent variables. However, the effectiveness of linear regression depends on several assumptions being met. Here are some of the key assumptions of linear regression:\n",
    "\n",
    "Linearity: The relationship between the dependent variable and the independent variable(s) is linear. This means that the change in the dependent variable is proportional to the change in the independent variable(s).\n",
    "\n",
    "Independence: The observations are independent of each other. This means that there is no relationship between the errors or residuals of the regression model.\n",
    "\n",
    "Homoscedasticity: The variance of the errors is constant across all levels of the independent variable(s). This means that the spread of the residuals is the same at all levels of the independent variable(s).\n",
    "\n",
    "Normality: The errors are normally distributed. This means that the residuals follow a normal distribution, with a mean of zero.\n",
    "\n",
    "No multicollinearity: The independent variables are not highly correlated with each other. This means that there is no redundancy in the independent variables.\n",
    "\n",
    "To check whether these assumptions hold in a given dataset, we can use a variety of techniques. Here are some common methods:\n",
    "\n",
    "Residual plots: A residual plot shows the residuals (i.e., the difference between the observed values and the predicted values) against the independent variable(s) or the predicted values. A good residual plot should show no pattern or trend, indicating that the linearity assumption holds.\n",
    "\n",
    "Normal probability plot: A normal probability plot shows the residuals against the expected normal distribution. A good normal probability plot should show the residuals following a straight line, indicating that the normality assumption holds.\n",
    "\n",
    "Leverage plots: A leverage plot shows the leverage values (i.e., the influence of each data point on the regression line) against the independent variable(s) or the predicted values. A good leverage plot should show no outliers or high-leverage points, indicating that the independence assumption holds.\n",
    "\n",
    "Variance inflation factor (VIF): VIF measures the degree of multicollinearity among the independent variables. A VIF value greater than 10 indicates high multicollinearity, which violates the no multicollinearity assumption.\n",
    "\n",
    "In summary, checking the assumptions of linear regression is an important step in ensuring the validity of the results. By using various diagnostic plots and tests, we can determine whether the assumptions hold and take appropriate steps to address any violations of the assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa91e8e4",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using \n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2615ba3",
   "metadata": {},
   "source": [
    "In a linear regression model, the slope and intercept represent the relationship between the dependent variable and the independent variable(s). The intercept (also known as the constant) is the predicted value of the dependent variable when the independent variable(s) are equal to zero. The slope represents the change in the dependent variable for each unit change in the independent variable(s).\n",
    "\n",
    "For example, consider a real-world scenario where we want to predict a person's weight (dependent variable) based on their height (independent variable). We can fit a linear regression model to the data and obtain the following equation:\n",
    "\n",
    "Weight = 50 + 0.6 * Height\n",
    "\n",
    "Here, the intercept is 50, which means that if a person has a height of zero, their weight would be predicted to be 50 kg. The slope is 0.6, which means that for each additional centimeter of height, the person's weight is predicted to increase by 0.6 kg.\n",
    "\n",
    "To interpret the slope and intercept, we can use the example equation above. Suppose we have a person with a height of 170 cm. We can plug in this value into the equation and obtain:\n",
    "\n",
    "Weight = 50 + 0.6 * 170 = 50 + 102 = 152 kg\n",
    "\n",
    "This means that for a person with a height of 170 cm, their weight is predicted to be 152 kg based on the linear regression model.\n",
    "\n",
    "Similarly, we can interpret the intercept as the weight of a hypothetical person with a height of zero, which is not realistic in this scenario. The slope indicates how much the weight is expected to increase for each additional centimeter of height.\n",
    "\n",
    "In summary, the slope and intercept in a linear regression model represent the relationship between the dependent variable and the independent variable(s), and can be used to make predictions or draw conclusions about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79702026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 4.7912918438168255\n",
      "Slope: 2.0283302727815937\n",
      "For every one unit increase in X, y increases by 2.0283302727815937\n",
      "When X is zero, y is predicted to be 4.7912918438168255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate random data\n",
    "X = np.random.rand(100, 1) * 10\n",
    "y = 2 * X + 5 + np.random.normal(0, 1, (100, 1))\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = LinearRegression().fit(X, y)\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"Intercept:\", model.intercept_[0])\n",
    "print(\"Slope:\", model.coef_[0][0])\n",
    "\n",
    "# Interpret the coefficients\n",
    "print(\"For every one unit increase in X, y increases by\", model.coef_[0][0])\n",
    "print(\"When X is zero, y is predicted to be\", model.intercept_[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0418e20",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3273a08f",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm that is commonly used in machine learning to minimize the cost function of a model. The cost function measures how well the model is able to predict the output values given the input features. The goal of gradient descent is to find the set of parameters (weights and biases) that minimize the cost function.\n",
    "\n",
    "The basic idea of gradient descent is to iteratively adjust the parameters in the direction of the negative gradient of the cost function. The negative gradient represents the direction of steepest descent, or the direction that leads to the largest decrease in the cost function. By moving the parameters in this direction, we can update the model to make better predictions.\n",
    "\n",
    "The process of gradient descent involves the following steps:\n",
    "\n",
    "Initialize the parameters of the model with some arbitrary values.\n",
    "Calculate the gradient of the cost function with respect to the parameters.\n",
    "Update the parameters by subtracting a fraction of the gradient from the current parameter values. The fraction is called the learning rate and determines the step size of the update.\n",
    "Repeat steps 2 and 3 until the cost function converges to a minimum.\n",
    "Gradient descent can be used with different types of models, including linear regression, logistic regression, and neural networks. In machine learning, the cost function is typically a function of the model parameters, which means that the gradient can be calculated using the chain rule of calculus. The learning rate is a hyperparameter that needs to be tuned carefully, as a too-small value can lead to slow convergence, while a too-large value can lead to overshooting the minimum of the cost function.\n",
    "\n",
    "In summary, gradient descent is an optimization algorithm used in machine learning to update the parameters of a model to minimize the cost function. It works by iteratively adjusting the parameters in the direction of the negative gradient of the cost function, using a learning rate to control the step size of the update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258aea9",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e6440",
   "metadata": {},
   "source": [
    "Multiple linear regression is a statistical technique used to model the relationship between a dependent variable and two or more independent variables. In contrast to simple linear regression, which models the relationship between a dependent variable and a single independent variable, multiple linear regression allows us to account for the effects of multiple variables on the dependent variable.\n",
    "\n",
    "The multiple linear regression model can be represented as follows:\n",
    "\n",
    "Y = β0 + β1X1 + β2X2 + ... + βkXk + ε\n",
    "\n",
    "where:\n",
    "\n",
    "Y is the dependent variable\n",
    "β0 is the intercept\n",
    "β1, β2, ..., βk are the coefficients for the independent variables X1, X2, ..., Xk, respectively\n",
    "ε is the error term\n",
    "The model assumes that the relationship between Y and the independent variables is linear, and that the error term ε is normally distributed with mean zero and constant variance.\n",
    "\n",
    "To estimate the coefficients of the model, we use a method called least squares, which minimizes the sum of the squared differences between the predicted values of Y and the actual values of Y. The least squares method involves calculating the partial derivatives of the cost function with respect to each of the coefficients, and then solving for the coefficients that minimize the cost function.\n",
    "\n",
    "Compared to simple linear regression, multiple linear regression allows us to model more complex relationships between the dependent variable and the independent variables, and to account for the effects of multiple variables simultaneously. However, it also requires more data and more complex calculations, and may suffer from multicollinearity if the independent variables are highly correlated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a1f782",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and \n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca43672",
   "metadata": {},
   "source": [
    "Multicollinearity is a problem that can occur in multiple linear regression when two or more independent variables are highly correlated with each other. This can cause problems in the estimation of the regression coefficients, leading to unreliable or unstable parameter estimates.\n",
    "\n",
    "One way to detect multicollinearity is to calculate the correlation matrix between the independent variables. If there are high correlations between pairs of independent variables, this indicates the presence of multicollinearity. Another way to detect multicollinearity is to calculate the variance inflation factor (VIF) for each independent variable. VIF measures how much the variance of the estimated coefficient is increased due to multicollinearity. A VIF value greater than 5 or 10 is considered to indicate a high degree of multicollinearity.\n",
    "\n",
    "To address the issue of multicollinearity, we can take several steps. One approach is to remove one or more of the highly correlated independent variables from the model. Another approach is to use regularization methods such as ridge regression or lasso regression, which penalize large coefficients and can help to stabilize the parameter estimates. A third approach is to perform a principal component analysis (PCA) to identify linear combinations of the independent variables that capture most of the variation in the data, and then use these principal components as the input variables for the regression.\n",
    "\n",
    "In summary, multicollinearity is a problem that can occur in multiple linear regression when two or more independent variables are highly correlated with each other. It can be detected using correlation matrices or VIF values, and addressed through variable selection, regularization, or principal component analysis. Addressing multicollinearity is important to ensure the reliability and stability of the regression coefficients and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779e50a",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998eb3e",
   "metadata": {},
   "source": [
    "Polynomial regression is a type of regression analysis in which the relationship between the independent variable (x) and the dependent variable (y) is modeled as an nth degree polynomial. In other words, the model assumes that the relationship between x and y is not linear, but can be described by a curved line.\n",
    "\n",
    "The polynomial regression model is different from the linear regression model in that it allows for more complex relationships between x and y. While linear regression assumes a linear relationship between x and y, polynomial regression can capture more complex relationships, such as quadratic or cubic relationships.\n",
    "\n",
    "To illustrate the difference between linear and polynomial regression, consider the following example: Suppose we want to model the relationship between a person's age (x) and their income (y). If we use linear regression, we would assume that the relationship between age and income is linear, i.e., that income increases or decreases at a constant rate as age increases. However, if we use polynomial regression, we could model the relationship as a curve, which could capture more complex patterns in the data, such as an increase in income until a certain age, followed by a decrease.\n",
    "\n",
    "In summary, polynomial regression is a type of regression analysis that allows for more complex relationships between the independent and dependent variables, by modeling the relationship as an nth degree polynomial. This is different from linear regression, which assumes a linear relationship between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f20501",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear \n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40aafc",
   "metadata": {},
   "source": [
    "Advantages of polynomial regression over linear regression:\n",
    "\n",
    "Captures non-linear relationships: Polynomial regression can capture non-linear relationships between the independent and dependent variables, whereas linear regression assumes a linear relationship. This makes it a more flexible model that can better fit certain types of data.\n",
    "\n",
    "More accurate predictions: In cases where the true relationship between the variables is non-linear, polynomial regression can provide more accurate predictions than linear regression.\n",
    "\n",
    "Disadvantages of polynomial regression compared to linear regression:\n",
    "\n",
    "Overfitting: Polynomial regression can easily overfit the data if the degree of the polynomial is too high. This can result in a model that fits the training data very well but does not generalize well to new data.\n",
    "\n",
    "Interpretability: The coefficients in a polynomial regression model can be difficult to interpret, especially if the degree of the polynomial is high.\n",
    "\n",
    "When to use polynomial regression:\n",
    "Polynomial regression is useful when we suspect that the relationship between the independent and dependent variables is non-linear. It can capture more complex relationships than linear regression and provide more accurate predictions in these cases. However, we need to be careful not to overfit the data by choosing an appropriate degree of polynomial. In general, we should start with a low degree polynomial and gradually increase the degree while monitoring the performance on a validation set.\n",
    "\n",
    "In summary, polynomial regression is a more flexible model that can capture non-linear relationships between variables and provide more accurate predictions in certain cases. However, we need to be careful not to overfit the data and choose an appropriate degree of polynomial. If the relationship between the variables is truly linear, then linear regression is still the better choice as it is simpler and easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce0371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
